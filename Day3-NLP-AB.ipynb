{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e82a3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74025b4",
   "metadata": {},
   "source": [
    "## 1. Natural Language Processing - A Naive Example\n",
    "\n",
    "Before diving into real Twitter data, let’s start with a simple example.\n",
    "Here’s a small corpus consisting of three short documents:\n",
    "\n",
    "- Document 1: It is going to rain today.\n",
    "- Document 2: Today I am not going outside.\n",
    "- Document 3: I am going to watch the season premiere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8024a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is going to rain today.', 'Today I am not going outside.', 'I am going to watch the season premiere.']\n"
     ]
    }
   ],
   "source": [
    "Document1= \"It is going to rain today.\"\n",
    "Document2= \"Today I am not going outside.\"\n",
    "Document3= \"I am going to watch the season premiere.\"\n",
    "Doc = [Document1 ,\n",
    " Document2 , \n",
    " Document3]\n",
    "print(Doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847ad76",
   "metadata": {},
   "source": [
    "\n",
    "From this example, we’ll learn how to convert raw text into numerical features — or what we might call columns of numbers. This process is often referred to as vectorization.\n",
    "\n",
    "Once we represent text as vectors, we unlock the ability to perform various types of analysis, including:\n",
    "- Summarization\n",
    "- Clustering\n",
    "- Topic modeling\n",
    "- Information retrieval (e.g., finding similar texts)\n",
    "- Predictive modeling\n",
    "\n",
    "The core idea in Natural Language Processing (NLP) is transforming unstructured text into structured numerical form. While there are many ways to do this, we’ll focus on one of the most widely used and interpretable methods: TF-IDF (Term Frequency–Inverse Document Frequency).\n",
    "\n",
    "TF-IDF is useful in many NLP applications. For example:\n",
    "- Search engines use it to rank the relevance of a document to a search query.\n",
    "- It’s also used in text classification, summarization, and topic modeling.\n",
    "\n",
    "After learning TF-IDF, we’ll apply it in a downstream task — topic modeling — to uncover hidden themes across the documents.\n",
    "\n",
    "While we won’t cover every vectorization technique or downstream task, this example will give you a strong foundation for understanding how an NLP pipeline works.\n",
    "\n",
    "\n",
    "### 1.1 Vectorization: Term Frequency(TF) — Inverse Document Frequency(IDF) Vectorization\n",
    "A corpus can be defined as a collection of documents. In our example, each sentence is a document, and they collectively form a corpus.  \n",
    "\n",
    "To vectorize text data, we use a TF-IDF method. \n",
    "- We first tokenize the text, and then assign an importance score for every term. \n",
    "- The importance score of a term is high when it occurs a lot in a given document and rarely in others. \n",
    "- In short, commonality within a document measured by TF is balanced by rarity between documents measured by IDF. The resulting TF-IDF score reflects the importance of a term for a document in the corpus.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50a02001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 ['it', 'is', 'going', 'to', 'rain', 'today']\n",
      "Document 2 ['today', 'am', 'not', 'going', 'outside']\n",
      "Document 3 ['am', 'going', 'to', 'watch', 'the', 'season', 'premiere']\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 18 stored elements and shape (3, 13)>\n",
      "  Coords\tValues\n",
      "  (0, 3)\t0.4711101009983051\n",
      "  (0, 2)\t0.4711101009983051\n",
      "  (0, 1)\t0.2782452148327134\n",
      "  (0, 10)\t0.35829137488557944\n",
      "  (0, 7)\t0.4711101009983051\n",
      "  (0, 11)\t0.35829137488557944\n",
      "  (1, 1)\t0.3154441510317797\n",
      "  (1, 11)\t0.4061917781433946\n",
      "  (1, 0)\t0.4061917781433946\n",
      "  (1, 4)\t0.5340933749435833\n",
      "  (1, 5)\t0.5340933749435833\n",
      "  (2, 1)\t0.2517108425440014\n",
      "  (2, 10)\t0.3241235393856436\n",
      "  (2, 0)\t0.3241235393856436\n",
      "  (2, 12)\t0.42618350336974425\n",
      "  (2, 9)\t0.42618350336974425\n",
      "  (2, 8)\t0.42618350336974425\n",
      "  (2, 6)\t0.42618350336974425\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>going</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>not</th>\n",
       "      <th>outside</th>\n",
       "      <th>premiere</th>\n",
       "      <th>rain</th>\n",
       "      <th>season</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>today</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278245</td>\n",
       "      <td>0.47111</td>\n",
       "      <td>0.47111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.47111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358291</td>\n",
       "      <td>0.358291</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.406192</td>\n",
       "      <td>0.315444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.534093</td>\n",
       "      <td>0.534093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406192</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324124</td>\n",
       "      <td>0.251711</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426184</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.426184</td>\n",
       "      <td>0.426184</td>\n",
       "      <td>0.324124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         am     going       is       it       not   outside  premiere  \\\n",
       "0  0.000000  0.278245  0.47111  0.47111  0.000000  0.000000  0.000000   \n",
       "1  0.406192  0.315444  0.00000  0.00000  0.534093  0.534093  0.000000   \n",
       "2  0.324124  0.251711  0.00000  0.00000  0.000000  0.000000  0.426184   \n",
       "\n",
       "      rain    season       the        to     today     watch  \n",
       "0  0.47111  0.000000  0.000000  0.358291  0.358291  0.000000  \n",
       "1  0.00000  0.000000  0.000000  0.000000  0.406192  0.000000  \n",
       "2  0.00000  0.426184  0.426184  0.324124  0.000000  0.426184  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer() #TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "analyze = vectorizer.build_analyzer()\n",
    "print(\"Document 1\",analyze(Document1))\n",
    "print(\"Document 2\",analyze(Document2))\n",
    "print(\"Document 3\",analyze(Document3))\n",
    "\n",
    "X = vectorizer.fit_transform(Doc)\n",
    "\n",
    "print(X)\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f3473",
   "metadata": {},
   "source": [
    "\n",
    "We tokenize and generate a vocab of the document. For each document, we can find the TF= (Number of repetitions of word in a document) / (# of words in a document). We can further find the IDF=Log[(Number of documents) / (Number of documents containing the word)]\n",
    "\n",
    "| words      | Doc1 | Doc2| Doc3|IDF Value|\n",
    "| ----------- | ----------- |----------- |----------- |----------- |\n",
    "| going      | 0.16     |0.16|0.12|0|\n",
    "| to   | 0.16       |0|0.12|0.41|\n",
    "|today|0.16|0.16|0|0.41|\n",
    "|i|0|0.16|0.12|0.41|\n",
    "|am|0|0.16|0.12|0.41|\n",
    "|it|0.16|0|0|1.09|\n",
    "|is |0.16|0|0|1.09|\n",
    "|rain|0.16|0|0|1.09|\n",
    "\n",
    "We then construct a document-term matrix using the TF-IDF scores:\n",
    "\n",
    "| Docs      | going |to|today|i|am|it|is|rain|\n",
    "| ------ |------ |------ |------ |------ |------ |------ |------ |------ |\n",
    "| Doc1      | 0  |0.07|0.07|0|0|0.17|0.17|0.17|0.17|\n",
    "| Doc2   | 0  |0|0.07|0.07|0.07|0|0|0|\n",
    "|Doc3|0|0.05|0|0.05|0.05|0|0|0|\n",
    "\n",
    "It is easy to see that 'it', 'is', and 'rain' are important for Doc 1 but not Doc 2 or Doc 3. Each row of the document-term matrix can be thought of as a numeric representation of the documents, which we often term vectors. These numeric representations help you to find similarities between documents. \n",
    " \n",
    "> You might have noticed that stop words such as “to” and “is” are included above. These are usually filtered out in real-world NLP tasks because they don’t carry much meaning.\n",
    "\n",
    "To perform vectorization in Python, we use the <code>TfidfVectorizer</code> from the <code>sklearn</code> package.\n",
    "\n",
    "The steps are:\n",
    "- Create the vectorizer.\n",
    "- Fit it on your corpus.\n",
    "- Transform your corpus into vectors.\n",
    "\n",
    "The function **TfidfVectorizer** takes two parameters. \n",
    "- max_df is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\". For example:\n",
    "    - max_df = 0.50 means \"ignore terms that appear in more than 50% of the documents\".\n",
    "    - max_df = 25 means \"ignore terms that appear in more than 25 documents\".\n",
    "    - The default max_df is 1.0, which means \"ignore terms that appear in more than 100% of the documents\". Thus, the default setting does not ignore any terms.\n",
    "- min_df is used for removing terms that appear too infrequently. For example:\n",
    "    - min_df = 0.01 means \"ignore terms that appear in less than 1% of the documents\".\n",
    "    - min_df = 5 means \"ignore terms that appear in less than 5 documents\".\n",
    "    - The default min_df is 1, which means \"ignore terms that appear in less than 1 document\". Thus, the default setting does not ignore any terms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e450721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outside</th>\n",
       "      <th>premiere</th>\n",
       "      <th>rain</th>\n",
       "      <th>season</th>\n",
       "      <th>today</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.795961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outside  premiere      rain   season     today    watch\n",
       "0         0         0  0.795961        0  0.605349        0\n",
       "1  0.795961         0         0        0  0.605349        0\n",
       "2         0   0.57735         0  0.57735         0  0.57735"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=Doc\n",
    "#Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=0.1, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023bb20b",
   "metadata": {},
   "source": [
    "Now, after removing stop words, the resulting matrix looks like this (we'll call it M):\n",
    "\n",
    "|     | outside   | premiere | rain     | season   | today    | watch    |\n",
    "|-----|-----------|----------|----------|----------|----------|----------|\n",
    "| 0   | 0         | 0        | 0.795961 | 0        | 0.605349 | 0        |\n",
    "| 1   | 0.795961  | 0        | 0        | 0        | 0.605349 | 0        |\n",
    "| 2   | 0         | 0.57735  | 0        | 0.57735  | 0        | 0.57735  |\n",
    "\n",
    "\n",
    "It is notable that <code>tfidf</code> is a sparse matrix. If you'd like to view it as a full DataFrame, use:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d2879c",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 Non-negative Matrix Factorization (NMF)\n",
    "\n",
    "TF-IDF vectors are great, but high-dimensional. When we have hundreds or thousands of terms, interpretation becomes difficult.\n",
    "\n",
    "To reduce this complexity and uncover latent themes, we use Non-negative Matrix Factorization (NMF), a powerful technique for **topic modeling**.\n",
    "\n",
    " If we think of the document-term matrix $M$ as a $m \\times n$ matrix with $m$ documents and $n$ terms, $M$ can be factorized as \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "M=W \\times H\n",
    "$$\n",
    "\n",
    "- M: Original document-term matrix (e.g., m docs × n terms)\n",
    "- W: Document-topic matrix (m docs × k topics)\n",
    "- H: Topic-term matrix (k topics × n terms)\n",
    "- k: Number of topics\n",
    "\n",
    "NMF finds W and H such that their product approximates M, and all values remain non-negative.\n",
    "\n",
    "This technique helps extract topics from text — where each topic is a combination of words, and each document can belong to multiple topics with different strengths.\n",
    " \n",
    " \n",
    "\n",
    "The function NMF takes two parameters. \n",
    "- n_components is the number of topics\n",
    "- random_state controls the random number generator used in the attribute combining process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7fd174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81058158 0.         0.81058158 0.         1.23293637 0.        ]\n",
      "[1 3 5 0 2 4]\n",
      "Topic #0:\n",
      "today rain outside\n",
      "[0.         0.68727788 0.         0.68727788 0.         0.68727788]\n",
      "[0 2 4 1 3 5]\n",
      "Topic #1:\n",
      "watch season premiere\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outside</th>\n",
       "      <th>premiere</th>\n",
       "      <th>rain</th>\n",
       "      <th>season</th>\n",
       "      <th>today</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.810582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.232936</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outside  premiere      rain    season     today     watch\n",
       "0  0.810582  0.000000  0.810582  0.000000  1.232936  0.000000\n",
       "1  0.000000  0.687278  0.000000  0.687278  0.000000  0.687278"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(n_components=2, random_state=0)\n",
    "#nmf_model.fit(tfidf)\n",
    "W = nmf_model.fit_transform(tfidf)  # Document-topic matrix\n",
    "\n",
    "# Display topics\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topic_names=[]\n",
    "# Assume nmf_model and feature_names are already defined\n",
    "topic_names = []\n",
    "\n",
    "# Loop through each topic\n",
    "for topic_index in range(len(nmf_model.components_)):\n",
    "    topic = nmf_model.components_[topic_index]\n",
    "    print(topic)\n",
    "    # Get the indices of the top 3 words (largest values in the topic)\n",
    "    sorted_indices = topic.argsort()  # sorts from smallest to largest\n",
    "\n",
    "    print(sorted_indices)\n",
    "    top_indices = sorted_indices[-3:]  # get the last 3 (top 3 words)\n",
    "    \n",
    "    # Reverse to make it largest to smallest\n",
    "    top_indices = top_indices[::-1]\n",
    "\n",
    "    # Get the actual word names for these indices\n",
    "    top_words = []\n",
    "    for i in top_indices:\n",
    "        top_words.append(feature_names[i])\n",
    "    \n",
    "    # Join the top words into a single string\n",
    "    top_words_string = \" \".join(top_words)\n",
    "\n",
    "    # Print and save\n",
    "    print(\"Topic #{}:\".format(topic_index))\n",
    "    print(top_words_string)\n",
    "    topic_names.append(top_words_string)\n",
    "topic_df = pd.DataFrame(W, columns=topic_names)\n",
    "topic_df\n",
    "\n",
    "topic_df = pd.DataFrame(nmf_model.components_ ,columns=feature_names)\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee934b1",
   "metadata": {},
   "source": [
    "This is the W matrix (document-topic distribution):\n",
    "\n",
    "\n",
    "|     | today outside rain | watch season premiere |\n",
    "|-----|--------------------|------------------------|\n",
    "| 0   | 0.490981           | 0.000000               |\n",
    "| 1   | 0.490981           | 0.000000               |\n",
    "| 2   | 0.000000           | 0.840054               |\n",
    "\n",
    "And this is the H matrix (topic-word distribution):\n",
    "\n",
    "|     | outside   | premiere | rain     | season   | today    | watch    |\n",
    "|-----|-----------|----------|----------|----------|----------|----------|\n",
    "| 0   | 0.810582  | 0.000000 | 0.810582 | 0.000000 | 1.232936 | 0.000000 |\n",
    "| 1   | 0.000000  | 0.687278 | 0.000000 | 0.687278 | 0.000000 | 0.687278 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d00b2",
   "metadata": {},
   "source": [
    "\n",
    "## 2 Analyzing Twitter Data\n",
    "\n",
    "Finally, we get to practice using the Twitter data! \n",
    "### 2.1 What Social Media Accounts to Search?\n",
    "\n",
    "To identify social media accounts related to AI tools, we perform a Google search using the keyword \"AI marketing tools\". Below are the Search Engine Results Pages (also known as “SERPs” or “SERP”).\n",
    "\n",
    "The first few results are sponsored links, and one organic result points us to [15 Best AI Marketing Tools in 2023-2024](https://improvado.io/blog/best-ai-marketing-tools). Among the recommended AI tools, we are particularly interested in [Grammarly](https://twitter.com/Grammarly). Let's collect tweets generated by Grammarly's official account and examine which tweets get more likes.\n",
    "\n",
    "\n",
    "> Grammarly is a cloud-based typing assistant. It reviews spelling, grammar, punctuation, clarity, engagement, and delivery mistakes in English texts, detects plagiarism, and suggests replacements for the identified errors. For a brief introduction to Grammarly, watch this [video](https://www.youtube.com/watch?v=zd64pGNLjVY).\n",
    "\n",
    "\n",
    "### 2.2. Data Collection\n",
    "Twitter has its API service. To simplify this data collection process, I built a little package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101d77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade --force-reinstall git+https://github.com/tantantan12/itom6219.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d82460e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>created_at</th>\n",
       "      <th>public_metrics.followers_count</th>\n",
       "      <th>public_metrics.following_count</th>\n",
       "      <th>public_metrics.tweet_count</th>\n",
       "      <th>public_metrics.listed_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.media_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47191725</td>\n",
       "      <td>Grammarly</td>\n",
       "      <td>Grammarly</td>\n",
       "      <td>Good writing moves work forward. #StandWithUkr...</td>\n",
       "      <td>True</td>\n",
       "      <td>2009-06-14T22:23:52.000Z</td>\n",
       "      <td>227923</td>\n",
       "      <td>3455</td>\n",
       "      <td>41476</td>\n",
       "      <td>2848</td>\n",
       "      <td>21049</td>\n",
       "      <td>9977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       name   username  \\\n",
       "0  47191725  Grammarly  Grammarly   \n",
       "\n",
       "                                         description  verified  \\\n",
       "0  Good writing moves work forward. #StandWithUkr...      True   \n",
       "\n",
       "                 created_at  public_metrics.followers_count  \\\n",
       "0  2009-06-14T22:23:52.000Z                          227923   \n",
       "\n",
       "   public_metrics.following_count  public_metrics.tweet_count  \\\n",
       "0                            3455                       41476   \n",
       "\n",
       "   public_metrics.listed_count  public_metrics.like_count  \\\n",
       "0                         2848                      21049   \n",
       "\n",
       "   public_metrics.media_count  \n",
       "0                        9977  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"BEARER_TOKEN\"] = \"AAAAAAAAAAAAAAAAAAAAAA7fGwEAAAAATek8qNEHmKiwy5NeLLGGLu%2FOllc%3DvMI6a81TOlLcj6fthUgm5xT66tHGcKYcklMRLcRZjxQBKpqWJp\"\n",
    "\n",
    "\n",
    "from itom6219 import user_info, user_tweets, user_tweets_all\n",
    "user=user_info([\"grammarly\"])\n",
    "user\n",
    "#tweets=user_tweets([\"grammarly\"], exclude_replies=True, exclude_retweets=True)\n",
    "\n",
    "#tweets_all=user_tweets_all([\"sunomusic\",\"TSwiftLyricsBot\"],max_total=1000, exclude_replies=True, exclude_retweets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f420f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=user_tweets([\"grammarly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d61a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>public_metrics.bookmark_count</th>\n",
       "      <th>public_metrics.impression_count</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>1942327975266992252</td>\n",
       "      <td>2025-07-07T21:00:50.000Z</td>\n",
       "      <td>@isamirDM Wow, Ibrahim—81 weeks strong! 💪 Big ...</td>\n",
       "      <td>1942285580127330508</td>\n",
       "      <td>810445800081936385</td>\n",
       "      <td>[1942327975266992252]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>1942307581965525412</td>\n",
       "      <td>2025-07-07T19:39:48.000Z</td>\n",
       "      <td>RT @tbpn: TBPN | Monday, July 7th https://t.co...</td>\n",
       "      <td>1942307581965525412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1942307581965525412]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>1940809006550798352</td>\n",
       "      <td>2025-07-03T16:25:00.000Z</td>\n",
       "      <td>@alliswell4usai Thrilled to be part of your wr...</td>\n",
       "      <td>1940709842370678930</td>\n",
       "      <td>1859531083357786112</td>\n",
       "      <td>[1940809006550798352]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zxx</td>\n",
       "      <td>1940112480799531218</td>\n",
       "      <td>2025-07-01T18:17:15.000Z</td>\n",
       "      <td>RT @Superhuman: https://t.co/5GQSDJDgIj</td>\n",
       "      <td>1940112480799531218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1940112480799531218]</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>1940077687697285341</td>\n",
       "      <td>2025-07-01T15:59:00.000Z</td>\n",
       "      <td>Grammarly has announced its intent to acquire ...</td>\n",
       "      <td>1940077687697285341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1940077687697285341]</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>264</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>226107</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>en</td>\n",
       "      <td>1886708018080817385</td>\n",
       "      <td>2025-02-04T09:26:59.000Z</td>\n",
       "      <td>@LTJ81 50 million words? What an incredible mi...</td>\n",
       "      <td>1886517350259703972</td>\n",
       "      <td>1411004539</td>\n",
       "      <td>[1886708018080817385]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>en</td>\n",
       "      <td>1886366614213333159</td>\n",
       "      <td>2025-02-03T10:50:22.000Z</td>\n",
       "      <td>@Ali_Khazaeei Hello! A member of our team has ...</td>\n",
       "      <td>1885948056710897717</td>\n",
       "      <td>1877370407151611906</td>\n",
       "      <td>[1886366614213333159]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>en</td>\n",
       "      <td>1884976520428454352</td>\n",
       "      <td>2025-01-30T14:46:38.000Z</td>\n",
       "      <td>@patrahgichobi That’s what we love to hear! Ke...</td>\n",
       "      <td>1884939768879800660</td>\n",
       "      <td>836501780158689280</td>\n",
       "      <td>[1884976520428454352]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>en</td>\n",
       "      <td>1884730492051955984</td>\n",
       "      <td>2025-01-29T22:29:00.000Z</td>\n",
       "      <td>RT @itsnicethat: Clear communication: explore ...</td>\n",
       "      <td>1884730492051955984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1884730492051955984]</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>en</td>\n",
       "      <td>1884021510911987940</td>\n",
       "      <td>2025-01-27T23:31:46.000Z</td>\n",
       "      <td>RT @shishirmehrotra: Orange and green sure do ...</td>\n",
       "      <td>1884021510911987940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1884021510911987940]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Grammarly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang                   id                created_at  \\\n",
       "0    en  1942327975266992252  2025-07-07T21:00:50.000Z   \n",
       "1    en  1942307581965525412  2025-07-07T19:39:48.000Z   \n",
       "2    en  1940809006550798352  2025-07-03T16:25:00.000Z   \n",
       "3   zxx  1940112480799531218  2025-07-01T18:17:15.000Z   \n",
       "4    en  1940077687697285341  2025-07-01T15:59:00.000Z   \n",
       "..  ...                  ...                       ...   \n",
       "95   en  1886708018080817385  2025-02-04T09:26:59.000Z   \n",
       "96   en  1886366614213333159  2025-02-03T10:50:22.000Z   \n",
       "97   en  1884976520428454352  2025-01-30T14:46:38.000Z   \n",
       "98   en  1884730492051955984  2025-01-29T22:29:00.000Z   \n",
       "99   en  1884021510911987940  2025-01-27T23:31:46.000Z   \n",
       "\n",
       "                                                 text      conversation_id  \\\n",
       "0   @isamirDM Wow, Ibrahim—81 weeks strong! 💪 Big ...  1942285580127330508   \n",
       "1   RT @tbpn: TBPN | Monday, July 7th https://t.co...  1942307581965525412   \n",
       "2   @alliswell4usai Thrilled to be part of your wr...  1940709842370678930   \n",
       "3             RT @Superhuman: https://t.co/5GQSDJDgIj  1940112480799531218   \n",
       "4   Grammarly has announced its intent to acquire ...  1940077687697285341   \n",
       "..                                                ...                  ...   \n",
       "95  @LTJ81 50 million words? What an incredible mi...  1886517350259703972   \n",
       "96  @Ali_Khazaeei Hello! A member of our team has ...  1885948056710897717   \n",
       "97  @patrahgichobi That’s what we love to hear! Ke...  1884939768879800660   \n",
       "98  RT @itsnicethat: Clear communication: explore ...  1884730492051955984   \n",
       "99  RT @shishirmehrotra: Orange and green sure do ...  1884021510911987940   \n",
       "\n",
       "    in_reply_to_user_id edit_history_tweet_ids  public_metrics.retweet_count  \\\n",
       "0    810445800081936385  [1942327975266992252]                             1   \n",
       "1                   NaN  [1942307581965525412]                             8   \n",
       "2   1859531083357786112  [1940809006550798352]                             0   \n",
       "3                   NaN  [1940112480799531218]                            24   \n",
       "4                   NaN  [1940077687697285341]                            30   \n",
       "..                  ...                    ...                           ...   \n",
       "95           1411004539  [1886708018080817385]                             0   \n",
       "96  1877370407151611906  [1886366614213333159]                             0   \n",
       "97   836501780158689280  [1884976520428454352]                             0   \n",
       "98                  NaN  [1884730492051955984]                             6   \n",
       "99                  NaN  [1884021510911987940]                             4   \n",
       "\n",
       "    public_metrics.reply_count  public_metrics.like_count  \\\n",
       "0                            1                          1   \n",
       "1                            0                          0   \n",
       "2                            0                          1   \n",
       "3                            0                          0   \n",
       "4                           19                        264   \n",
       "..                         ...                        ...   \n",
       "95                           1                          1   \n",
       "96                           0                          0   \n",
       "97                           0                          2   \n",
       "98                           0                          0   \n",
       "99                           0                          0   \n",
       "\n",
       "    public_metrics.quote_count  public_metrics.bookmark_count  \\\n",
       "0                            0                              0   \n",
       "1                            0                              0   \n",
       "2                            0                              0   \n",
       "3                            0                              0   \n",
       "4                           38                             65   \n",
       "..                         ...                            ...   \n",
       "95                           0                              0   \n",
       "96                           0                              0   \n",
       "97                           0                              0   \n",
       "98                           0                              0   \n",
       "99                           0                              0   \n",
       "\n",
       "    public_metrics.impression_count   username  \n",
       "0                                25  Grammarly  \n",
       "1                                 0  Grammarly  \n",
       "2                                32  Grammarly  \n",
       "3                                 1  Grammarly  \n",
       "4                            226107  Grammarly  \n",
       "..                              ...        ...  \n",
       "95                               71  Grammarly  \n",
       "96                               38  Grammarly  \n",
       "97                              124  Grammarly  \n",
       "98                                1  Grammarly  \n",
       "99                                1  Grammarly  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b690864e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities.mentions</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>public_metrics.bookmark_count</th>\n",
       "      <th>public_metrics.impression_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @Infosys: We are delighted to announce the ...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1749406750195773...</td>\n",
       "      <td>1760971102103490795</td>\n",
       "      <td>5.451676e+07</td>\n",
       "      <td>['1760971102103490795']</td>\n",
       "      <td>2024-02-23T10:13:22.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 11, 'username': 'Infosys'...</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @edwardlimp: @rovercrc The problem is you m...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1760967808882762...</td>\n",
       "      <td>1760970913397309573</td>\n",
       "      <td>1.661782e+18</td>\n",
       "      <td>['1760970913397309573']</td>\n",
       "      <td>2024-02-23T10:12:37.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 14, 'username': 'edwardli...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @BrnMetaverse: 💡 $BRN is everywhere\\n\\n🚀 We...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1760318913848504...</td>\n",
       "      <td>1760970867607998725</td>\n",
       "      <td>2.753974e+09</td>\n",
       "      <td>['1760970867607998725']</td>\n",
       "      <td>2024-02-23T10:12:26.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 16, 'username': 'BrnMetav...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @kortizart: The Biden Harris administration...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1760820176780775...</td>\n",
       "      <td>1760970809063960931</td>\n",
       "      <td>3.688994e+09</td>\n",
       "      <td>['1760970809063960931']</td>\n",
       "      <td>2024-02-23T10:12:12.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 13, 'username': 'kortizar...</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A thread of all GenAI projects that I have bui...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1760970779888419317</td>\n",
       "      <td>1.371103e+18</td>\n",
       "      <td>['1760970779888419317']</td>\n",
       "      <td>2024-02-23T10:12:05.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>RT @AINN_BRC20: 🎉 Thrilled to announce $AINN j...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1760653986879697...</td>\n",
       "      <td>1762415592211144938</td>\n",
       "      <td>1.642337e+18</td>\n",
       "      <td>['1762415592211144938']</td>\n",
       "      <td>2024-02-27T09:53:15.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 14, 'username': 'AINN_BRC...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>@CryptoThro Missing $CODEX @codex_token 💎👀 \\n\\...</td>\n",
       "      <td>[{'type': 'replied_to', 'id': '176238891087584...</td>\n",
       "      <td>1762415571033858182</td>\n",
       "      <td>1.744319e+18</td>\n",
       "      <td>['1762415571033858182']</td>\n",
       "      <td>2024-02-27T09:53:10.000Z</td>\n",
       "      <td>[{'start': 0, 'end': 11, 'username': 'CryptoTh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.738088e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>RT @rafatamames: Hoy como TopVoice escribo est...</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1762412235740119...</td>\n",
       "      <td>1762415568823443879</td>\n",
       "      <td>3.145352e+08</td>\n",
       "      <td>['1762415568823443879']</td>\n",
       "      <td>2024-02-27T09:53:10.000Z</td>\n",
       "      <td>[{'start': 3, 'end': 15, 'username': 'rafatama...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Offered my perspective on some of @Google’s Ge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1762415548661477535</td>\n",
       "      <td>2.085956e+08</td>\n",
       "      <td>['1762415548661477535']</td>\n",
       "      <td>2024-02-27T09:53:05.000Z</td>\n",
       "      <td>[{'start': 34, 'end': 41, 'username': 'Google'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>In Cardiff for @BBCWales 2030 conference. Firs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1762415541984133520</td>\n",
       "      <td>3.002373e+08</td>\n",
       "      <td>['1762415541984133520']</td>\n",
       "      <td>2024-02-27T09:53:03.000Z</td>\n",
       "      <td>[{'start': 15, 'end': 24, 'username': 'BBCWale...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    RT @Infosys: We are delighted to announce the ...   \n",
       "1    RT @edwardlimp: @rovercrc The problem is you m...   \n",
       "2    RT @BrnMetaverse: 💡 $BRN is everywhere\\n\\n🚀 We...   \n",
       "3    RT @kortizart: The Biden Harris administration...   \n",
       "4    A thread of all GenAI projects that I have bui...   \n",
       "..                                                 ...   \n",
       "496  RT @AINN_BRC20: 🎉 Thrilled to announce $AINN j...   \n",
       "497  @CryptoThro Missing $CODEX @codex_token 💎👀 \\n\\...   \n",
       "498  RT @rafatamames: Hoy como TopVoice escribo est...   \n",
       "499  Offered my perspective on some of @Google’s Ge...   \n",
       "500  In Cardiff for @BBCWales 2030 conference. Firs...   \n",
       "\n",
       "                                     referenced_tweets                   id  \\\n",
       "0    [{'type': 'retweeted', 'id': '1749406750195773...  1760971102103490795   \n",
       "1    [{'type': 'retweeted', 'id': '1760967808882762...  1760970913397309573   \n",
       "2    [{'type': 'retweeted', 'id': '1760318913848504...  1760970867607998725   \n",
       "3    [{'type': 'retweeted', 'id': '1760820176780775...  1760970809063960931   \n",
       "4                                                  NaN  1760970779888419317   \n",
       "..                                                 ...                  ...   \n",
       "496  [{'type': 'retweeted', 'id': '1760653986879697...  1762415592211144938   \n",
       "497  [{'type': 'replied_to', 'id': '176238891087584...  1762415571033858182   \n",
       "498  [{'type': 'retweeted', 'id': '1762412235740119...  1762415568823443879   \n",
       "499                                                NaN  1762415548661477535   \n",
       "500                                                NaN  1762415541984133520   \n",
       "\n",
       "        author_id   edit_history_tweet_ids                created_at  \\\n",
       "0    5.451676e+07  ['1760971102103490795']  2024-02-23T10:13:22.000Z   \n",
       "1    1.661782e+18  ['1760970913397309573']  2024-02-23T10:12:37.000Z   \n",
       "2    2.753974e+09  ['1760970867607998725']  2024-02-23T10:12:26.000Z   \n",
       "3    3.688994e+09  ['1760970809063960931']  2024-02-23T10:12:12.000Z   \n",
       "4    1.371103e+18  ['1760970779888419317']  2024-02-23T10:12:05.000Z   \n",
       "..            ...                      ...                       ...   \n",
       "496  1.642337e+18  ['1762415592211144938']  2024-02-27T09:53:15.000Z   \n",
       "497  1.744319e+18  ['1762415571033858182']  2024-02-27T09:53:10.000Z   \n",
       "498  3.145352e+08  ['1762415568823443879']  2024-02-27T09:53:10.000Z   \n",
       "499  2.085956e+08  ['1762415548661477535']  2024-02-27T09:53:05.000Z   \n",
       "500  3.002373e+08  ['1762415541984133520']  2024-02-27T09:53:03.000Z   \n",
       "\n",
       "                                     entities.mentions  \\\n",
       "0    [{'start': 3, 'end': 11, 'username': 'Infosys'...   \n",
       "1    [{'start': 3, 'end': 14, 'username': 'edwardli...   \n",
       "2    [{'start': 3, 'end': 16, 'username': 'BrnMetav...   \n",
       "3    [{'start': 3, 'end': 13, 'username': 'kortizar...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "496  [{'start': 3, 'end': 14, 'username': 'AINN_BRC...   \n",
       "497  [{'start': 0, 'end': 11, 'username': 'CryptoTh...   \n",
       "498  [{'start': 3, 'end': 15, 'username': 'rafatama...   \n",
       "499  [{'start': 34, 'end': 41, 'username': 'Google'...   \n",
       "500  [{'start': 15, 'end': 24, 'username': 'BBCWale...   \n",
       "\n",
       "     public_metrics.retweet_count  public_metrics.reply_count  \\\n",
       "0                           709.0                         0.0   \n",
       "1                            10.0                         0.0   \n",
       "2                            60.0                         0.0   \n",
       "3                           398.0                         0.0   \n",
       "4                             0.0                         1.0   \n",
       "..                            ...                         ...   \n",
       "496                         156.0                         0.0   \n",
       "497                           0.0                         0.0   \n",
       "498                           1.0                         0.0   \n",
       "499                           0.0                         0.0   \n",
       "500                           4.0                         0.0   \n",
       "\n",
       "     public_metrics.like_count  public_metrics.quote_count  \\\n",
       "0                          0.0                         0.0   \n",
       "1                          0.0                         0.0   \n",
       "2                          0.0                         0.0   \n",
       "3                          0.0                         0.0   \n",
       "4                          7.0                         0.0   \n",
       "..                         ...                         ...   \n",
       "496                        0.0                         0.0   \n",
       "497                        0.0                         0.0   \n",
       "498                        0.0                         0.0   \n",
       "499                        0.0                         0.0   \n",
       "500                       10.0                         0.0   \n",
       "\n",
       "     public_metrics.bookmark_count  public_metrics.impression_count  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              0.0   \n",
       "4                              9.0                            865.0   \n",
       "..                             ...                              ...   \n",
       "496                            0.0                              0.0   \n",
       "497                            0.0                              1.0   \n",
       "498                            0.0                              0.0   \n",
       "499                            0.0                             82.0   \n",
       "500                            0.0                            602.0   \n",
       "\n",
       "     in_reply_to_user_id  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "..                   ...  \n",
       "496                  NaN  \n",
       "497         2.738088e+09  \n",
       "498                  NaN  \n",
       "499                  NaN  \n",
       "500                  NaN  \n",
       "\n",
       "[501 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use pd.read_csv to read csv file\n",
    "file_path = 'AI_tweets_all.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911e535",
   "metadata": {},
   "source": [
    "## 3 Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "564bde96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>00pm</th>\n",
       "      <th>10</th>\n",
       "      <th>1000</th>\n",
       "      <th>100xgems</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>15000</th>\n",
       "      <th>1dnzjoqndy</th>\n",
       "      <th>1m</th>\n",
       "      <th>...</th>\n",
       "      <th>どこが</th>\n",
       "      <th>なのか</th>\n",
       "      <th>なるほど</th>\n",
       "      <th>のようなフルオプトイン型契約の画像生成aiの存在を概ね今の利用者は無視しているんで詭弁に付き合う必要は無いと思います</th>\n",
       "      <th>ほうほうほう</th>\n",
       "      <th>フリーライドでき</th>\n",
       "      <th>元から許諾済みのみのgenaiがあるのに</th>\n",
       "      <th>急速にサーチのuxが置き換わると予想されてる</th>\n",
       "      <th>生成aiによる技術の発展</th>\n",
       "      <th>青線はgenaiによるアンサークエリー数で</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 1033 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  00pm   10  1000  100xgems   12   14  15000  1dnzjoqndy   1m  ...  \\\n",
       "0    0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "1    0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "2    0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "3    0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "4    0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "..   ...   ...  ...   ...       ...  ...  ...    ...         ...  ...  ...   \n",
       "496  0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "497  0.0   0.0  0.0   0.0  0.197348  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "498  0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "499  0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "500  0.0   0.0  0.0   0.0  0.000000  0.0  0.0    0.0         0.0  0.0  ...   \n",
       "\n",
       "     どこが  なのか  なるほど  \\\n",
       "0    0.0  0.0   0.0   \n",
       "1    0.0  0.0   0.0   \n",
       "2    0.0  0.0   0.0   \n",
       "3    0.0  0.0   0.0   \n",
       "4    0.0  0.0   0.0   \n",
       "..   ...  ...   ...   \n",
       "496  0.0  0.0   0.0   \n",
       "497  0.0  0.0   0.0   \n",
       "498  0.0  0.0   0.0   \n",
       "499  0.0  0.0   0.0   \n",
       "500  0.0  0.0   0.0   \n",
       "\n",
       "     のようなフルオプトイン型契約の画像生成aiの存在を概ね今の利用者は無視しているんで詭弁に付き合う必要は無いと思います  ほうほうほう  \\\n",
       "0                                                  0.0              0.0   \n",
       "1                                                  0.0              0.0   \n",
       "2                                                  0.0              0.0   \n",
       "3                                                  0.0              0.0   \n",
       "4                                                  0.0              0.0   \n",
       "..                                                 ...              ...   \n",
       "496                                                0.0              0.0   \n",
       "497                                                0.0              0.0   \n",
       "498                                                0.0              0.0   \n",
       "499                                                0.0              0.0   \n",
       "500                                                0.0              0.0   \n",
       "\n",
       "     フリーライドでき  元から許諾済みのみのgenaiがあるのに  急速にサーチのuxが置き換わると予想されてる  生成aiによる技術の発展  \\\n",
       "0         0.0                   0.0                     0.0           0.0   \n",
       "1         0.0                   0.0                     0.0           0.0   \n",
       "2         0.0                   0.0                     0.0           0.0   \n",
       "3         0.0                   0.0                     0.0           0.0   \n",
       "4         0.0                   0.0                     0.0           0.0   \n",
       "..        ...                   ...                     ...           ...   \n",
       "496       0.0                   0.0                     0.0           0.0   \n",
       "497       0.0                   0.0                     0.0           0.0   \n",
       "498       0.0                   0.0                     0.0           0.0   \n",
       "499       0.0                   0.0                     0.0           0.0   \n",
       "500       0.0                   0.0                     0.0           0.0   \n",
       "\n",
       "     青線はgenaiによるアンサークエリー数で  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "..                     ...  \n",
       "496                    0.0  \n",
       "497                    0.0  \n",
       "498                    0.0  \n",
       "499                    0.0  \n",
       "500                    0.0  \n",
       "\n",
       "[501 rows x 1033 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=df['text']\n",
    "#Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a0b0a",
   "metadata": {},
   "source": [
    "## 3.4 Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d94cc8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "airdrop 000 10 genai\n",
      "Topic #1:\n",
      "genai_offi 5az6vq9msvjaxeinzp2nmwzh66mvtsjum3qiuxgvegkk rqdfwz3n3opcbwu87mxkkwaxj5xyv9fszvju8u6en5j aywxyybyfhoya9ewkwjwssjfcb6frevshnbhwhkcmrde\n",
      "Topic #2:\n",
      "genai sp4fxn6bor genaimemechallenge bullish\n",
      "Topic #3:\n",
      "codex utilities 100xgems 5o6m40ifkj\n",
      "Topic #4:\n",
      "https ai marketing genai\n",
      "Topic #5:\n",
      "gem getting kai guys\n",
      "Topic #6:\n",
      "00pm boom b² ama\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airdrop 000 10 genai</th>\n",
       "      <th>genai_offi 5az6vq9msvjaxeinzp2nmwzh66mvtsjum3qiuxgvegkk rqdfwz3n3opcbwu87mxkkwaxj5xyv9fszvju8u6en5j aywxyybyfhoya9ewkwjwssjfcb6frevshnbhwhkcmrde</th>\n",
       "      <th>genai sp4fxn6bor genaimemechallenge bullish</th>\n",
       "      <th>codex utilities 100xgems 5o6m40ifkj</th>\n",
       "      <th>https ai marketing genai</th>\n",
       "      <th>gem getting kai guys</th>\n",
       "      <th>00pm boom b² ama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.004619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.000624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076822</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>0.007667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.005431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.050524</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.005094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016118</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.038531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     airdrop 000 10 genai  \\\n",
       "0                0.009723   \n",
       "1                0.002644   \n",
       "2                0.001476   \n",
       "3                0.000000   \n",
       "4                0.011300   \n",
       "..                    ...   \n",
       "496              0.002289   \n",
       "497              0.000000   \n",
       "498              0.000693   \n",
       "499              0.002414   \n",
       "500              0.004980   \n",
       "\n",
       "     genai_offi 5az6vq9msvjaxeinzp2nmwzh66mvtsjum3qiuxgvegkk rqdfwz3n3opcbwu87mxkkwaxj5xyv9fszvju8u6en5j aywxyybyfhoya9ewkwjwssjfcb6frevshnbhwhkcmrde  \\\n",
       "0                                             0.000000                                                                                                  \n",
       "1                                             0.000084                                                                                                  \n",
       "2                                             0.000000                                                                                                  \n",
       "3                                             0.000000                                                                                                  \n",
       "4                                             0.000000                                                                                                  \n",
       "..                                                 ...                                                                                                  \n",
       "496                                           0.000000                                                                                                  \n",
       "497                                           0.000000                                                                                                  \n",
       "498                                           0.000157                                                                                                  \n",
       "499                                           0.000000                                                                                                  \n",
       "500                                           0.000000                                                                                                  \n",
       "\n",
       "     genai sp4fxn6bor genaimemechallenge bullish  \\\n",
       "0                                       0.019345   \n",
       "1                                       0.002855   \n",
       "2                                       0.000000   \n",
       "3                                       0.000000   \n",
       "4                                       0.034387   \n",
       "..                                           ...   \n",
       "496                                     0.004224   \n",
       "497                                     0.000000   \n",
       "498                                     0.005944   \n",
       "499                                     0.004520   \n",
       "500                                     0.016118   \n",
       "\n",
       "     codex utilities 100xgems 5o6m40ifkj  https ai marketing genai  \\\n",
       "0                               0.000000                  0.041931   \n",
       "1                               0.000000                  0.019999   \n",
       "2                               0.000000                  0.041276   \n",
       "3                               0.000000                  0.076822   \n",
       "4                               0.000000                  0.095493   \n",
       "..                                   ...                       ...   \n",
       "496                             0.000000                  0.008777   \n",
       "497                             0.522019                  0.000000   \n",
       "498                             0.000403                  0.050524   \n",
       "499                             0.000000                  0.094671   \n",
       "500                             0.000158                  0.038531   \n",
       "\n",
       "     gem getting kai guys  00pm boom b² ama  \n",
       "0                0.006715          0.000000  \n",
       "1                0.016787          0.004619  \n",
       "2                0.007060          0.000624  \n",
       "3                0.003809          0.007667  \n",
       "4                0.000000          0.000000  \n",
       "..                    ...               ...  \n",
       "496              0.009289          0.005431  \n",
       "497              0.000000          0.000000  \n",
       "498              0.008150          0.005094  \n",
       "499              0.000000          0.000000  \n",
       "500              0.000000          0.000000  \n",
       "\n",
       "[501 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Apply NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(n_components=7, random_state=0)\n",
    "nmf_model.fit(tfidf)\n",
    "W = nmf_model.fit_transform(tfidf)  # Document-topic matrix\n",
    "\n",
    "# Display topics\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "topic_names=[]\n",
    "for topic_index in range(len(nmf_model.components_)):\n",
    "    topic = nmf_model.components_[topic_index]\n",
    "    # Get the indices of the top 3 words (largest values in the topic)\n",
    "    sorted_indices = topic.argsort()  # sorts from smallest to largest\n",
    "    top_indices = sorted_indices[-4:]  # get the last 3 (top 3 words)\n",
    "    # Reverse to make it largest to smallest\n",
    "    top_indices = top_indices[::-1]\n",
    "    # Get the actual word names for these indices\n",
    "    top_words = []\n",
    "    for i in top_indices:\n",
    "        top_words.append(feature_names[i])\n",
    "    # Join the top words into a single string\n",
    "    top_words_string = \" \".join(top_words)\n",
    "    # Print and save\n",
    "    print(\"Topic #{}:\".format(topic_index))\n",
    "    print(top_words_string)\n",
    "    topic_names.append(top_words_string)\n",
    "\n",
    "topic_df = pd.DataFrame(W, columns=topic_names)\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc250f82",
   "metadata": {},
   "source": [
    "\n",
    "## 4 Linear Regression\n",
    "\n",
    "Linear regression is one of the most commonly used techniques in data analysis. It helps us understand the relationship between one or more input variables (features) and an output variable (target). In the simplest case, it tries to draw a straight line that best fits the data.\n",
    "\n",
    "In our example, we want to understand:\n",
    "\n",
    "- How do the topics of Grammarly’s tweets influence the number of likes?\n",
    "- Which topics are more likely to lead to higher engagement (likes)?\n",
    "- Which topics seem to have less impact or even negative impact?\n",
    "\n",
    "Each tweet is represented as a set of topic weights (from NMF), and our target is the like count for that tweet.\n",
    "\n",
    "We’ll use the topic weights (<code>topic_df</code>) as features, and the like count (<code>df['public_metrics.like_count']</code>) as the target.\n",
    "\n",
    "\n",
    "The model assumes a relationship of the form:\n",
    "\n",
    "$$\n",
    "\\text{Like\\_Count} = \\beta_0 + \\beta_1 \\cdot \\text{Topic}_1 + \\beta_2 \\cdot \\text{Topic}_2 + \\dots + \\beta_k \\cdot \\text{Topic}_k\n",
    "$$\n",
    "\n",
    "- $\\beta_0$ is the intercept.  \n",
    "- $\\beta_1, \\beta_2, \\dots, \\beta_k$ are **coefficients** for each topic.  \n",
    "- A **positive coefficient** ($\\beta_i > 0$) means the topic is associated with **more likes**.  \n",
    "- A **negative coefficient** ($\\beta_i < 0$) means the topic is associated with **fewer likes**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "640b68b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Target (y) contains NaN or Inf. Please remove them manually or use remove_na=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m df_model[\u001b[33m'\u001b[39m\u001b[33mratio\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mpublic_metrics.like_count\u001b[39m\u001b[33m'\u001b[39m] / df[\u001b[33m'\u001b[39m\u001b[33mlog_view\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Run linear regression\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m result = \u001b[43mpg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mratio\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_model\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mratio\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Round coef and pval to 3 decimal places\u001b[39;00m\n\u001b[32m     11\u001b[39m result[[\u001b[33m'\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcoef\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpval\u001b[39m\u001b[33m'\u001b[39m]] = result[[\u001b[33m'\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcoef\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpval\u001b[39m\u001b[33m'\u001b[39m]].round(\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pingouin/regression.py:338\u001b[39m, in \u001b[36mlinear_regression\u001b[39m\u001b[34m(X, y, add_intercept, weights, coef_only, alpha, as_dataframe, remove_na, relimp)\u001b[39m\n\u001b[32m    336\u001b[39m y_gd = np.isfinite(y).all()\n\u001b[32m    337\u001b[39m X_gd = np.isfinite(X).all()\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m y_gd, (\n\u001b[32m    339\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mTarget (y) contains NaN or Inf. Please remove them \u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mmanually or use remove_na=True.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m )\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m X_gd, (\n\u001b[32m    342\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPredictors (X) contain NaN or Inf. Please remove them \u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mmanually or use remove_na=True.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    343\u001b[39m )\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# Check that X and y have same length\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: Target (y) contains NaN or Inf. Please remove them manually or use remove_na=True."
     ]
    }
   ],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Combine X and y into a single dataframe\n",
    "df_model = topic_df.copy()\n",
    "df_model['ratio'] = df['public_metrics.like_count'] / df['log_view']\n",
    "\n",
    "# Run linear regression\n",
    "result = pg.linear_regression(df_model.drop(columns='ratio'), df_model['ratio'])\n",
    "\n",
    "# Round coef and pval to 3 decimal places\n",
    "result[['names', 'coef', 'pval']] = result[['names', 'coef', 'pval']].round(3)\n",
    "\n",
    "# Display the rounded result\n",
    "result[['names', 'coef', 'pval']]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
